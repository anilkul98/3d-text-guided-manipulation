{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182369a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"using cuda\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0738b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.shapenet import ShapeNetVox\n",
    "\n",
    "# Create a dataset with train split\n",
    "trainset = ShapeNetVox('train')\n",
    "valset = ShapeNetVox('val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1f36bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 02691156/97c12e6155fdf8ca90baeef8ba5b93e5\n",
      "Voxel Dimensions: (1, 32, 32, 32)\n",
      "Label: 0 | 02691156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccb6a4d36a54f0cbd3cb63bb4fac00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util.visualization import visualize_occupancy\n",
    "\n",
    "shape_data = trainset[2]\n",
    "print(f'Name: {shape_data[\"name\"]}')  # expected output: 04379243/d120d47f8c9bc5028640bc5712201c4a\n",
    "print(f'Voxel Dimensions: {shape_data[\"voxel\"].shape}')  # expected output: (1, 32, 32, 32)\n",
    "print(f'Label: {shape_data[\"label\"]} | {ShapeNetVox.classes[shape_data[\"label\"]]}')  # expected output: 10, 04379243\n",
    "\n",
    "visualize_occupancy(shape_data[\"voxel\"].squeeze(), flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "addede5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import _G, _D\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_params = {\"cube_len\" : 32,\n",
    "               \"z_size\": 256}\n",
    "\n",
    "train_loader = DataLoader(trainset,  batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(valset,  batch_size=16, shuffle=True)\n",
    "\n",
    "G = _G(model_params)\n",
    "D = _D(model_params)\n",
    "\n",
    "G.to(device)\n",
    "D.to(device)\n",
    "\n",
    "D_optim = optim.Adam(D.parameters(), lr=1e-3)\n",
    "G_optim = optim.Adam(G.parameters(), lr=1e-3)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae56251",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 32, 32, 32])\n",
      "torch.Size([16, 32, 16, 16, 16])\n",
      "torch.Size([16, 64, 8, 8, 8])\n",
      "torch.Size([16, 128, 4, 4, 4])\n",
      "torch.Size([16, 256, 2, 2, 2])\n",
      "torch.Size([16, 1, 1, 1, 1])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1, 1, 1, 1])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_149710/3925373465.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0md_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#         print(d_real.shape, real_labels.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0md_real_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry-3m7GBFwI-py3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry-3m7GBFwI-py3.7/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry-3m7GBFwI-py3.7/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3086\u001b[0m         raise ValueError(\n\u001b[1;32m   3087\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3088\u001b[0;31m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3089\u001b[0m         )\n\u001b[1;32m   3090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1, 1, 1, 1])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(10):\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    d_acc = []\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = batch[\"voxel\"].to(device)\n",
    "\n",
    "#             if batch.size()[0] != int(args.batch_size):\n",
    "#                 #print(\"batch_size != {} drop last incompatible batch\".format(int(args.batch_size)))\n",
    "#                 continue\n",
    "\n",
    "        Z = torch.Tensor(16, model_params[\"z_size\"]).normal_(0, 0.33).to(device)\n",
    "        real_labels = torch.ones((16, )).to(device)\n",
    "        fake_labels = torch.zeros((16, )).to(device)\n",
    "\n",
    "        # ============= Train the discriminator =============#\n",
    "        d_real = D(batch)\n",
    "#         print(d_real.shape, real_labels.shape)\n",
    "        d_real = torch.squeeze(d_real)\n",
    "        d_real_loss = loss_fn(d_real, real_labels)\n",
    "\n",
    "\n",
    "        fake = G(Z)\n",
    "        d_fake = D(fake)\n",
    "        d_fake = torch.squeeze(d_fake)\n",
    "        d_fake_loss = loss_fn(d_fake, fake_labels)\n",
    "\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_losses.append(d_loss)\n",
    "\n",
    "        d_real_acu = torch.ge(d_real.squeeze(), 0.5).float()\n",
    "        d_fake_acu = torch.le(d_fake.squeeze(), 0.5).float()\n",
    "        d_total_acu = torch.mean(torch.cat((d_real_acu, d_fake_acu),0))\n",
    "        d_acc.append(d_total_acu)\n",
    "\n",
    "        if d_total_acu <= 0.8:\n",
    "            D.zero_grad()\n",
    "            d_loss.backward()\n",
    "            D_optim.step()\n",
    "\n",
    "        # =============== Train the generator ===============#\n",
    "\n",
    "        Z = torch.Tensor(16, model_params[\"z_size\"]).normal_(0, 0.33).to(device)\n",
    "\n",
    "        fake = G(Z)\n",
    "        d_fake = D(fake)\n",
    "        d_fake = torch.squeeze(d_fake)\n",
    "        g_loss = loss_fn(d_fake, real_labels)\n",
    "        g_losses.append(g_loss)\n",
    "\n",
    "        D.zero_grad()\n",
    "        G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        G_optim.step()\n",
    "    \n",
    "    torch.save(G.state_dict(), \"output_models/G_{}\".format(epoch))\n",
    "    torch.save(D.state_dict(), \"output_models/D_{}\".format(epoch))\n",
    "    epoch_dloss = np.mean(np.array(d_losses))\n",
    "    epoch_gloss = np.mean(np.array(g_losses))\n",
    "    epoch_dacc = np.mean(np.array(d_acc))\n",
    "    print(f\"Epoch: {epoch}, d_loss: {epoch_dloss}, g_loss: {epoch_gloss}, dacc: {epoch_dacc}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73bd837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
